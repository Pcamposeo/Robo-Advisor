{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 05\n",
    "### Team Member Names: Piero Camposeo, Sathun Suthakaran, Ishaan Bansal\n",
    "### Team Strategy Chosen: SAFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "We want to generate an unusually \"safe\" short-term portfolio. Rather than maximize returns, we want to keep returns as close as possible to zero. The goal is to generate a portfolio, based on a random set of tickers, whose projected value over an arbitrary number of days is as close to its starting value as possible. Specifically, our code is made for a 5-day run-time of the portfolio, but the model used is viable for any short period (though, as the investment horizon gets longer, this method may not be the most accurate compared to other pricing models such as a normal CAPM due to short-term assumptions we make).\n",
    "\n",
    "The code is split into four sections:\n",
    "\n",
    "1. DATA CLEANING\n",
    "2. CHOOSING THE STOCKS\n",
    "3. CREATING THE OPTIMAL PORTFOLIO\n",
    "4. ANALYSIS AND SANITY / CORRECTNESS CHECKS\n",
    "\n",
    "Data cleaning involves removing tickers that do not fit certain criteria, chosen by the user.\n",
    "\n",
    "Choosing the stocks involves picking the least volatile tickers, which we will utilize in our final portfolio.\n",
    "\n",
    "Creating the portfolio involves generating randomly weighted portfolios, comprised of our selection of tickers (Based on the first two parts). The final portfolio will be that which has the expected return closest to 0. We will calculate expected return based on a <b>modified Multi-Security Capital Asset Pricing Model</b> (below), whereby we assume the risk-free rate to be zero (since this model should be used for a short time horizon, we expect the variation between the market and risk-free rate to be immaterial) and multiply the market's expected return by the sum of the products of each securities' respective weight and beta.\n",
    "\n",
    "![Modified, Multi-Security CAPM](Pricing-Model-Image.png)\n",
    "\n",
    "The code should output the final portfolio and share count to a .csv file.\n",
    "\n",
    "Analysis and sanity checks involve visual representations to enhance comprehension, ensuring that the value of the portfolio is correct, as well as showing that the portfolio is indeed expected to return close to 0 over a short period of time, among other characteristics.\n",
    "\n",
    "Objective assumptions (As per assignment instructions):\n",
    "\n",
    "- Fractional shares can be purchased\n",
    "- There will be no transaction costs when buying stocks.\n",
    "- Once the portfolio is set, it cannot be changed.\n",
    "- Dividends will be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why CAPM?\n",
    "\n",
    "The Capital Asset Pricing Model (CAPM for short) gives the expected return for an asset relational to its risk with the market.\n",
    "\n",
    "One of the primary assumptions we make when deriving the desired portfolio for a short-term investment horizon is that <b>systematic risk will drive the majority of price volatility.</b> There are two reasons for this:\n",
    "\n",
    "1. Since we choose a large number of stocks to put in the portfolio, the portfolio will likely be diversified. This means there will be a lower probability of a high correlation between the securities we select, or volatility based on certain idiosyncratic events.\n",
    "\n",
    "2. Since we have a short-term investment horizon, there is little time for idiosyncratic risk factors to push our returns away from the goal.\n",
    "\n",
    "With this assumption in mind, we decided that the modified CAPM was the best pricing model to use for three reasons:\n",
    "\n",
    "1. It is a tested and proven model\n",
    "\n",
    "2. Including beta as a factor allows us to imply both correlation and risk into one variable\n",
    "\n",
    "3. Including beta as a factor, by nature will bias the allocation of capital towards stocks that have lower volatility (and therefore a lower beta)\n",
    "\n",
    "Some issues with other viable methods:\n",
    "\n",
    "1. Picking the portfolio with the lowest volatility\n",
    "- Doesn't consider correlation strongly. With this model, it's possible for the correlation between securities to be high and still yield low volatility, which could cause the direction of volatility to be stronger.\n",
    "\n",
    "2. Picking the portfolio with the lowest expected return (by combining the averages of the returns for each security)\n",
    "- Doesn't consider volatility heavily. The magnitude of volatility may be strong. For a short time horizon, this can be bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import threading\n",
    "import time\n",
    "from queue import Queue\n",
    "import random\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA CLEANING: \n",
    "\n",
    "The following cells are where the data cleaning happens.\n",
    "\n",
    "THE GOAL:\n",
    "\n",
    "• Ignore any tickers that do not reference a valid stock denominated in USD, i.e., we want to only use US-listed stocks.\n",
    "\n",
    "• Only use tickers that reference stocks with an average monthly volume of at least 200,000 shares, as calculated based on a specified time interval. A month is defined as a calendar month. We will drop any month that does not have at least 20 trading days.\n",
    "\n",
    "THE PROCESS:\n",
    "\n",
    "Firstly, we have chosen to implement multithreading, to speed up the process. The data cleaning is the most time-consuming code in the program to run (Due to the time it takes to send a request to the yfinance API). Because of this, we have two main functions (currency_check and volume_check), running on two separate threads, c and v. These functions are defined recursively; If too many tickers are passed into the function (i.e a list of tickers that is longer than the 'max_length_lst' variable in each function), the function calls on several threads to run the function with smaller, sub-lists. When a small enough quantity of tickers is passed to the function, it will perform the criteria check for the tickers. Valid tickers get passed to the function's respective queue. Finally, the queue is cleared, and tickers that fit both criteria are outputted and saved as our tickers.\n",
    "\n",
    "Note 1: Currency check generates more threads per application than volume_check because it takes significantly longer to run. This is also why its 'max_list_length' variable is smaller\n",
    "\n",
    "Note 2: For the sake of comparison, when tested by our team:\n",
    "\n",
    "- Unthreaded, non-recursive code takes ~13 minutes to run\n",
    "- Multithreaded, non-recursive code takes ~5-10 minutes to run\n",
    "- <b>Multithreaded, recursive code takes ~1 minute to run</b>\n",
    "\n",
    "Note 3: 'max_length_lst' may need to be updated for larger lists of tickers\n",
    "\n",
    "Our code checks each of the two criteria mentioned in the goal (one for each function) and generates two lists. Each list contains tickers that reference stocks that have satisfied the requirements of the functions. As we want stocks that fit both criteria, our final list of (valid) tickers is the set intersection of the two lists which each function produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in csv file of tickers\n",
    "csv_file = \"Example-of-Tickers.csv\"\n",
    "\n",
    "# Make values into a list\n",
    "tickers = pd.read_csv(csv_file)\n",
    "ticker_list = tickers.iloc[:, 0].values.tolist()\n",
    "ticker_list.insert(0, tickers.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consumes desired amount of trading days within a month, a DataFrame of days, a DataFrame of months, and a list of months that corresponds to the months\n",
    "#    on the DataFrame, outputs the monthly DataFrame with only months that have 'daycount' amount of trading days for that stock\n",
    "#Note: Function will cover up to the last date. For example, the function will not produce October for a DataFrame which ends on October 1st.\n",
    "#   In our code, we simply passed a days DataFrame that ends one month after the months DataFrame does (^)\n",
    "def df_with_valid_months(daycount, df_days, df_months, months):\n",
    "    for month in range (len(months)):\n",
    "        if len(df_days.filter(like = months[month], axis = 0)) < daycount:\n",
    "            df_months.drop(df_months.index[month], axis = 0, inplace = True) #Drop any months with not enough trading days\n",
    "            \n",
    "    return(df_months)\n",
    "\n",
    "#Consumes historical data for a stock, outputs average volume\n",
    "def average_volume(df_hist):\n",
    "    volume = df_hist['Volume'].dropna().values.tolist()\n",
    "    vol_av = np.mean(volume)\n",
    "\n",
    "    return(vol_av)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates for volume calculation, end date for valid months function (see (^))\n",
    "vol_date_s = '2022-01-01'\n",
    "vol_date_e = '2022-10-02'\n",
    "endDForValidMonthsFunct = str((pd.to_datetime(vol_date_e) + relativedelta(months = 1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "#for df_with_valid_months function, creates a series of months from vol_date_s to vol_date_e\n",
    "months = pd.date_range(vol_date_s, vol_date_e, freq='MS').strftime(\"%Y-%m\").tolist()\n",
    "\n",
    "#As outlined in assignment information\n",
    "minimumMonthlyTradingDays = 20\n",
    "minimum_volume = 200000\n",
    "required_denomination = 'USD'\n",
    "\n",
    "#Here we will put valid stocks that fit our criteria\n",
    "tickers = []\n",
    "\n",
    "currency_valid = []\n",
    "volume_valid = []\n",
    "\n",
    "#Queue variables to store tickers\n",
    "queueC = Queue()\n",
    "queueV = Queue()\n",
    "\n",
    "#Consumes a list of tickers, used to check if they are denominated in 'required_denomination'.\n",
    "def currency_check(ticker_list):\n",
    "    max_length_lst = 5\n",
    "\n",
    "    #When there are an appropriate number of tickers in ticker_list, the function performs currency_check\n",
    "    if len(ticker_list) <= max_length_lst:\n",
    "\n",
    "        #Retrieve financial currency from each ticker. If it is 'required_denomination', it is a valid ticker. Else, we don't care so we set it as nan\n",
    "        for ticker in ticker_list:\n",
    "            tick = yf.Ticker(ticker)\n",
    "            try:\n",
    "                currency = tick.info['currency']\n",
    "            except:\n",
    "                currency = 'nan'\n",
    "        \n",
    "            #Check criteria, add to list of valid tickers for currency\n",
    "            if currency == required_denomination:\n",
    "                #Pass our valid tickers to the QueueC (Queue Currency), so that they may be called on later\n",
    "                queueC.put(ticker)\n",
    "\n",
    "    #If there are too many tickers in ticker_lst, we run a recursive application of currency_check with numthreads threads, with the arguments being one of\n",
    "    #numthreads equal parts of ticker_list  \n",
    "    else:\n",
    "        numthreads = 5\n",
    "\n",
    "        ticker_split = np.array_split(ticker_list, numthreads)\n",
    "\n",
    "        # Start numthreads threads, add to list \n",
    "        threads = []\n",
    "        for n in range(numthreads):\n",
    "            cSub = threading.Thread(target = currency_check, args = (ticker_split[n],))\n",
    "            cSub.start()\n",
    "            threads.append(cSub)\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        for t in threads:\n",
    "            t.join()\n",
    " \n",
    "#Consumes a list of tickers, used to check if they have an average monthly volume of 'minimum_volume' or more for months with\n",
    "#'minimumMonthlyTradingDays' or more trading days\n",
    "def volume_check(ticker_list):\n",
    "    max_length_lst = 20\n",
    "    \n",
    "    #When there are an appropriate number of tickers in ticker_list, the function performs currency_check\n",
    "    if len(ticker_list) <= max_length_lst:\n",
    "\n",
    "        for ticker in ticker_list:\n",
    "            tick = yf.Ticker(ticker)\n",
    "        \n",
    "            #Retrieve monthly average volume from each ticker. If it is greater than or equal to minimum_volume, it is a valid ticker. Else, we ignore it.\n",
    "            try:\n",
    "                #Check for Delisted ticker + Creating histories. If 'check' returns an error, the code continues. Without this try/except clause,\n",
    "                #Error code for delisted stock appears twice\n",
    "                tick_hist = tick.history(start = vol_date_s, end  = vol_date_e, interval = '1mo').dropna()\n",
    "                check = tick_hist.iloc[0,0]\n",
    "                #Custom dataframe for valid months check (daily, ending one month after monthly dataframe)\n",
    "                tickHistForValidMonthsCheck = tick.history(start = vol_date_s, end  = endDForValidMonthsFunct, interval = '1d').dropna()\n",
    " \n",
    "                #Dataframe with valid months only\n",
    "                tickHistWithValidMonths = df_with_valid_months(minimumMonthlyTradingDays, tickHistForValidMonthsCheck, tick_hist, months)\n",
    "\n",
    "                #Call on average_volume function to compute an average volume\n",
    "                monthly_average_volume = 0 #Initialize this to 0 to prevent errors\n",
    "                monthly_average_volume = average_volume(tickHistWithValidMonths)\n",
    "        \n",
    "                #Check criteria, add to list of valid tickers for volume\n",
    "                if monthly_average_volume >= minimum_volume:\n",
    "                    #Pass our valid tickers to the QueueV (Queue Volume), so that they may be called on later\n",
    "                    queueV.put(ticker)\n",
    "       \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    #If there are too many tickers in ticker_lst, we run a recursive application of volume_check with numthreads threads, with the arguments being one of\n",
    "    #numthreads equal parts of ticker_list    \n",
    "    else:\n",
    "        numthreads = 2\n",
    "\n",
    "        ticker_split = np.array_split(ticker_list, numthreads)\n",
    "\n",
    "        # Start numthreads threads, add to list \n",
    "        threads = []\n",
    "        for n in range(numthreads):\n",
    "            vSub = threading.Thread(target = volume_check, args = (ticker_split[n],))\n",
    "            vSub.start()\n",
    "            threads.append(vSub)\n",
    "\n",
    "        # Wait for all threads to finish.\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "#Creating threads for currency_check and volume_check function\n",
    "c = threading.Thread(target = currency_check, args = (ticker_list,))\n",
    "v = threading.Thread(target = volume_check, args = (ticker_list,))\n",
    "\n",
    "#Start thread executions\n",
    "c.start()\n",
    "v.start()\n",
    "\n",
    "#Wait for v to finish, grab all elements from queue\n",
    "v.join()\n",
    "while not queueV.empty():\n",
    "    volume_valid.append(queueV.get())\n",
    "\n",
    "\n",
    "#Wait for c to finish, grab all elements from queue\n",
    "c.join()\n",
    "while not queueC.empty():\n",
    "    currency_valid.append(queueC.get())\n",
    "\n",
    "#Valid tickers are the intersection of the two lists (Must have particular denomination and average monthly volume as outlined in assignment)\n",
    "tickers = sorted([value for value in currency_valid if value in volume_valid])\n",
    "\n",
    "print(f\"\\nValid Tickers: {tickers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHOOSING THE STOCKS:\n",
    "\n",
    "The following cells are where we choose the stocks to be used for the final portfolio.\n",
    "\n",
    "THE GOAL:\n",
    "\n",
    "Since our overall goal is to have a portfolio that finishes as close to its starting value as possible, we naturally want a diversified and stable selection of stocks. With this in mind, we decided to choose as many stocks as allowed (so as to avoid idiosyncratic risk), with the chosen stocks being the least volatile out of the available selection. Essentially, we want:\n",
    "\n",
    "• (if there are less than 25 tickers to choose from) Every (valid) ticker available <b>OR</b> 25 tickers (maximum allowed as outlined in assignment information) comprised of:\n",
    "\n",
    "• The least volatile stocks available\n",
    "\n",
    " • Note: Volatility, as we define it in this section, is represented by the standard deviation of daily returns (over a recent 5-month period, specifically)\n",
    "\n",
    "THE PROCESS:\n",
    "\n",
    "We will obtain closing data for each ticker, and calculate returns using the pct_change() function. Then, we will take the standard deviation of those returns and select the tickers with the lowest values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes in a list of valid tickers and returns 2 DataFrames -- one containing the tickers and their closing prices, and one containing the tickers and their respective percent returns. \n",
    "\n",
    "We iterate through the list of tickers and retrieve the closing prices of each stock from Yahoo Finance. The tickers serve as keys in the dictionary where the values are lists of tickers' corresponding closing prices. This dictionary is then converted to a DataFrame – the DataFrame of closing prices.\n",
    "\n",
    "Then we create a second dictionary where the keys are the tickers in the ticker list. We implement the 'pct_change' function on closing prices for each stock, yielding percent returns, which serve as the keys. This dictionary is converted into a second DataFrame - the DataFrame of percent returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFERENCE DATA - CHANGE BASED UPON INVESTMENT HORIZON\n",
    "#Here we have 5 months of historical data to calculate a 5-day portfolio\n",
    "start = '2022-06-20'\n",
    "end = '2022-11-20'\n",
    "\n",
    "#Creates a DataFrame of closing prices from start_date to end_date for ticker_list\n",
    "def get_closing_df(ticker_list, start_date, end_date):\n",
    "    #dictionary of closing prices\n",
    "    closing_dict = {}\n",
    "    #.history is not inclusive of end date, so we add one day\n",
    "    end_date =str((pd.to_datetime(end_date) + relativedelta(days = 1)).strftime(\"%Y-%m-%d\"))\n",
    "    interval = '1d'\n",
    "\n",
    "    #Fills closing_dict dictionary with closing prices for each ticker in closing_tickers\n",
    "    for ticker in ticker_list:\n",
    "        tick = yf.Ticker(ticker)\n",
    "        tick_hist = tick.history(start = start_date, end = end_date, interval = interval)\n",
    "\n",
    "        closing_dict[ticker] = tick_hist['Close']\n",
    "\n",
    "    closing_df = pd.DataFrame(closing_dict)\n",
    "\n",
    "    return(closing_df) \n",
    "\n",
    "#Creates a DataFrame of percent returns from start_date to end_date for a DataFrame of closing prices\n",
    "def get_returns_from_close_df(closing_df):\n",
    "    #Dictionary of returns\n",
    "    returns = {}\n",
    "\n",
    "    #Fills returns dictionary with the pct returns for each ticker in closing_df\n",
    "    for price in closing_df:\n",
    "        returns[price] = closing_df[price].pct_change()\n",
    "\n",
    "    returns_df = pd.DataFrame(returns)\n",
    "\n",
    "    return(returns_df)\n",
    "\n",
    "#We will use these for analysis\n",
    "tickers_closeDF = get_closing_df(tickers, start, end) \n",
    "tickers_returnDF = get_returns_from_close_df(tickers_closeDF)\n",
    "\n",
    "#print(\"Closing Prices Preview:\")\n",
    "#tickers_closeDF.head()\n",
    "\n",
    "print(\"Percent Returns Preview:\")\n",
    "tickers_returnDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes in the above percent return DataFrame and generates the standard deviation for each ticker. It stores this information in a new DataFrame, which is then sorted in increasing order. We select the first 25 tickers, or all of the tickers (whichever is less) to use in our final portfolio.\n",
    "\n",
    "We then use this final list of the tickers to filter our existing close prices and percent return DataFrames such that each only has values for each ticker in our list, and store these as new DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_portfolios = 25\n",
    "\n",
    "# Consumes a DataFrame of stocks and their respective daily % returns and produces a list of the 'max_portfolios' least volatile stocks, or if there's\n",
    "# Less than 'max_portfolios' stocks to choose from, produces a list of all of the stocks. Also prints DataFrame of final stocks and their respected\n",
    "# volatility, as well as the number of stocks in the final portfolio\n",
    "def lowest_volatile_stocks(pr_df, max_portfolios):\n",
    "    \n",
    "    all_stock_vol = []\n",
    "    numstocks_final = 0 #This stays 0 until changed by function\n",
    "\n",
    "    # Performs the calculations for every column\n",
    "    for pctchange in range (len(pr_df.columns)):\n",
    "        # Calculates the standard deviation of the stock's daily percent return\n",
    "        stock_vol = pr_df.iloc[:,pctchange].std()\n",
    "        \n",
    "        all_stock_vol.append(stock_vol)\n",
    "\n",
    "    # Creates a DataFrame that will store each stock and their volatility, sorts by non-decreasing volatility\n",
    "    all_stock_vol_df = pd.DataFrame({\"Stocks\": pr_df.columns, \"Daily % Returns Std\": all_stock_vol,})\n",
    "    all_stock_vol_df.sort_values(by = \"Daily % Returns Std\", inplace = True)\n",
    "    all_stock_vol_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    print(\"Preview of Final Selection of Stocks Daily Returns:\\n\")\n",
    "\n",
    "    #Creates a list of the 'max_portfolios' least volatile stocks in the DataFrame if there are more than 'max_portfolios', \n",
    "    #else creates a list of all of the stocks. Prints DataFrame\n",
    "    if len(all_stock_vol_df) > max_portfolios:\n",
    "        final_portfolio_lst = all_stock_vol_df['Stocks'].loc[0 : max_portfolios - 1].values.tolist()\n",
    "        numstocks_final = max_portfolios\n",
    "\n",
    "        print(all_stock_vol_df.iloc[0 : max_portfolios + 1].head())\n",
    "    else:\n",
    "        final_portfolio_lst = all_stock_vol_df['Stocks'].values.tolist()\n",
    "        numstocks_final = len(all_stock_vol_df)\n",
    "\n",
    "        print(all_stock_vol_df.head())\n",
    "\n",
    "    print(f\"\\nStocks in Portfolio ({numstocks_final}): \\n{final_portfolio_lst}\")\n",
    "    \n",
    "    return(final_portfolio_lst)\n",
    "\n",
    "ticklist_final = sorted(lowest_volatile_stocks(tickers_returnDF, max_portfolios))\n",
    "tickersReturn_final = tickers_returnDF[ticklist_final]\n",
    "tickersPrice_final = tickers_closeDF[ticklist_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CREATING THE OPTIMAL PORTFOLIO:\n",
    "\n",
    "The following cells are where we generate the portfolio whose expected return is as close to 0 as possible.\n",
    "\n",
    "THE GOAL:\n",
    "\n",
    "We want to use our modified CAPM to determine which allocation of capital yields the lowest absolute expected return.\n",
    "\n",
    "THE PROCESS:\n",
    "\n",
    "Since we want to use our modified CAPM as the basis for judgement, we first gather a set of custom betas, one for each ticker (based on an allocated period of historical data). We opt to not use the benchmark 5-year beta provided by Yahoo Finance, as we are focused on a short investment horizon (i.e we want to bias our data towards recent market activity). We then implement multithreading to efficiently generate one million portfolios, each with a different allocation of capital (weight) to each security. We save the CAPM score (expected return) of each weighting, as well as the best CAPM score and the weights associated with it. Finally, we generate a portfolio using a specified amount of capital, with each security being weighted according to the \"optimal weights\" (those that yield the lowest absolute CAPM score).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our portfolio_beta function takes in the new percent returns DataFrame, the stock used to represent the market, and the start and end date of the data being collected for the market stock (we use the same dates used to collect data for the tickers in the final portfolio).\n",
    "\n",
    "The function first creates a DataFrame storing the percent returns of the market stock and merges this DataFrame with the DataFrame containing the percent returns of the stocks to be used in the final portfolio.\n",
    "\n",
    "A matrix is then generated using the merged DataFrame, containing the beta of every stock in relation to another stock in the DataFrame. The beta value of each stock relative to the market is then stored in a new DataFrame which is returned with each index (ticker) lining up with the respective beta value.\n",
    "\n",
    "Finally, we store the beta values in a list that can be called later.\n",
    "\n",
    "We decided to use the NYSE (New York Stock Exchange) as our reference market here, as we believe it to be the most all-encompassing market (since it has a diverse set of stocks, as well as the most stocks). We assume that all tickers passed are US-listed, but the market which we are taking beta relative to can be changed if that is not the case, or if factors want to be considered (such as a list of only S&P 500 tickers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_market = \"^NYA\" #NYSE is what will be taking beta compared to\n",
    "\n",
    "#Consumes a DataFrame of the percent returns of stocks and a stock to represent the \"market\". It then returns the beta of each stock in the DataFrame\n",
    "#compared to the \"market\" inputted. The \"market\" stock must be a string of how the ticker appears in yfinance.\n",
    "def portfolio_beta(pr_df, market_stock, start, end):\n",
    "\n",
    "    # Creates a DataFrame of the percent returns of the stock representing the market\n",
    "    market = yf.Ticker(market_stock)\n",
    "    market_close = market.history(start = start, end = end, interval = \"1d\")['Close']\n",
    "    market_pr = market_close.pct_change()\n",
    "    market_pr_df = pd.DataFrame({market_stock: market_pr})\n",
    "    \n",
    "    # Merges pr_df and the market_pr_df together and drops the first row which is NaN values because there is no percent return for the first\n",
    "    #data point\n",
    "    beta_data = pr_df.merge(market_pr_df, left_index = True, right_index= True)\n",
    "    beta_data.drop(index=beta_data.index[0], inplace = True)\n",
    "\n",
    "    #Calculates the variance of the stock representing the market\n",
    "    MarketVar = market_pr_df[market_stock].var()\n",
    "    #Creates the beta matrix of the merged DataFrame\n",
    "    Beta_matrix = beta_data.cov()/MarketVar\n",
    "\n",
    "    #Prints Beta Matrix\n",
    "    #print(\"Portfolio's Beta Matrix Preview:\")\n",
    "    #print(Beta_matrix.head())\n",
    "\n",
    "    #DataFrame of the Betas of each stock\n",
    "    portfolio_stock_beta = pd.DataFrame({\"Beta\": Beta_matrix.iloc[:, (len(Beta_matrix) - 2)],})\n",
    "    portfolio_stock_beta.drop(market_stock, inplace = True)\n",
    "    \n",
    "    return(portfolio_stock_beta)\n",
    "\n",
    "portfolio_betas = portfolio_beta(tickersReturn_final, ref_market, start, end)\n",
    "beta_list = portfolio_betas['Beta'].values.tolist()\n",
    "\n",
    "#Prints the Beta of each stock\n",
    "print(\"Portfolio's Stocks' Betas Preview:\")\n",
    "portfolio_betas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have beta values for each ticker, we begin the process of finding the optimal portfolio. As previously mentioned, we will be using multithreading to generate one million portfolios, each with each security weighted differently. First, we find the market's expected return, which is a constant multiplier of our formula. Then, we utilize the np.dot() function to multiply each security's beta with its weight and add these quantities together. Multiplying these quantities by the market's expected return yields an expected return for the portfolio. We take note of the lowest expected return, and the weights associated with it, and generate a portfolio (the <b>optimal</b> portfolio). The value of this portfolio can then be tracked over time.\n",
    "\n",
    "<b>Drawbacks and room for improvement:</b> Due to the nature of statistical distribution, for a portfolio of 25 stocks, the number of generated portfolios with one or more stocks at a high weight (> 15%) is disproportionately low compared to the number of generated portfolios whose weights all sit around 4% (since 100% / 25 = an average of 4% per number). Better distribution could be implemented to truly test every possible portfolio weight (within a reasonable decimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves the closing prices of a list of tickers on a specific date\n",
    "def get_prices(ticker_list, price_date):\n",
    "    #Set end date to one day after target date (.history is non-inclusive of end date)\n",
    "    end_date = str((pd.to_datetime(price_date) + relativedelta(days = 1)).strftime(\"%Y-%m-%d\"))\n",
    "    prices = []\n",
    "    interval = '1d'\n",
    "\n",
    "    #Retrieve price from each ticker and store it in a list\n",
    "    for ticker in ticker_list:\n",
    "        tick = yf.Ticker(ticker)\n",
    "        price = tick.history(start = price_date, end = end_date, interval = interval)['Close'][0]\n",
    "        #Pass our valid tickers to the QueueP (Queue Price), so that they may be called on later\n",
    "        prices.append(price)\n",
    "\n",
    "    #Return list of prices\n",
    "    return(prices)\n",
    "\n",
    "#Generates a list of N numbers, summing to k, between max and min.\n",
    "#    Note: The distribution will be biased towards the mean (k / n). This function must be run many times to achieve values on each extreme, \n",
    "#          depending on variables passed\n",
    "def weight_generation(N, k, min, max): # *\n",
    "    assert(N * min <= k <= N * max)\n",
    "    adjusted_k = k - min * N\n",
    "    while True:\n",
    "        endpoints = sorted(uniform(0, adjusted_k) for i in range(N - 1))\n",
    "        values = [*(end - begin + min\n",
    "                    for begin, end in zip([0] + endpoints,\n",
    "                                          endpoints + [adjusted_k]))]\n",
    "        if all(v <= max for v in values):\n",
    "            return (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital = 500000\n",
    "num_hypothetical_portfolios = 1000000\n",
    "numperiods = 5 #For expected return - change to 1 to have one period expected return\n",
    "\n",
    "price_date = '2022-11-25'\n",
    "\n",
    "#Initializing queue for weights function, and list to store values\n",
    "queueW = Queue()\n",
    "queueWGetter = []\n",
    "\n",
    "#Generates 'num_ports' random weightings for a portfolio holding stocks in 'ticker_list'. Uses modified CAPM to generate weights of each ticker\n",
    "#whose expected return when combined in a portfolio is closest to zero\n",
    "def best_weighting(market_returns_list, ticker_list, beta_list, num_ports):\n",
    "   #Integers. Will be converted to decimals\n",
    "   lowest_weight = (100 / (2 * (len(ticker_list))))\n",
    "   highest_weight = 25\n",
    "\n",
    "   best_weights = []\n",
    "   best_capm_score = 10000 #Initialize to high number so that first portfolio will replace it\n",
    "   capm_scores = []\n",
    "\n",
    "   #Constant value\n",
    "   rm = np.mean(market_returns_list)\n",
    "\n",
    "   #for each index, i in set_information, i[0] will hold the best CAPM score, i[1] will hold the weights that yield that score, i[2] holds all CAPM scores.\n",
    "   set_information = []\n",
    "\n",
    "   #If there are an appropriate number of portfolios to be generated, function will perform weighting check\n",
    "   if num_ports <= 100000:\n",
    "\n",
    "      #Generate random weights, scale back\n",
    "      for i in range (0, num_ports):\n",
    "         weights = weight_generation(len(ticker_list), 100, lowest_weight, highest_weight)\n",
    "         weights = [(x / 100) for x in weights]\n",
    "\n",
    "         #Generate CAPM score (Expected return of portfolio), add to list\n",
    "         capm_score = rm * (np.dot(weights, beta_list)) #This is equivalent to the summation notation form\n",
    "         capm_scores.append(capm_score)\n",
    "\n",
    "         #Check for best CAPM score (closest to 0)\n",
    "         if abs(capm_score) < best_capm_score:\n",
    "            best_capm_score = capm_score\n",
    "            best_weights = weights\n",
    "\n",
    "      set_information.append(best_capm_score) \n",
    "      set_information.append(best_weights)\n",
    "      set_information.append(capm_scores)\n",
    "\n",
    "      #Puts set information into queueW to be retrieved later\n",
    "      queueW.put(set_information)\n",
    "\n",
    "   #If there are too many portfolios to be generated, function creates numthreads threads, each generating num_ports // numthreads portfolios\n",
    "   else:\n",
    "      numthreads = 10\n",
    "\n",
    "      num_ports_new = num_ports // numthreads\n",
    "\n",
    "      # Start numthreads threads\n",
    "      threads = []\n",
    "      for n in range(numthreads):\n",
    "         wSub = threading.Thread(target = best_weighting, args = (market_returns_list, ticker_list, beta_list, num_ports_new,))\n",
    "         wSub.start()\n",
    "         threads.append(wSub)\n",
    "\n",
    "      # Wait for all threads to finish.\n",
    "      for t in threads:\n",
    "         t.join()\n",
    "\n",
    "#Requires: index of weights match up with index of columns (i.e stock y in column x has weight z in index x)\n",
    "#Creates a portfolio with columns Ticker (ticker), Price (price as of price_date), Shares (shares to be bought based on capital and weight),\n",
    "#Value (price * shares), and Weights (weight of each stock)\n",
    "def create_weighted_portfolio(weights, price_df, capital, price_date):\n",
    "   shares = []\n",
    "   value = []\n",
    "   #As per assignment information, index of final portfolio begins at 1\n",
    "   index = list(range(1, (len(weights) + 1)))\n",
    "\n",
    "   #Closing price of each stock on price_date\n",
    "   prices = get_prices(price_df.columns, price_date)\n",
    "\n",
    "   #Calculating shares, value of stock in portfolio\n",
    "   for i in range (0, len(weights)):\n",
    "      shares.append((capital * weights[i]) / prices[i])\n",
    "      value.append(prices[i] * shares[i])\n",
    "\n",
    "   portfolio_final_dict = {'Ticker': price_df.columns,\n",
    "                        'Price': prices,\n",
    "                        'Shares': shares,\n",
    "                        'Value': value,\n",
    "                        'Weight': weights}\n",
    " \n",
    "   portfolio = pd.DataFrame(portfolio_final_dict)\n",
    "   portfolio.index = index\n",
    "\n",
    "   return(portfolio)\n",
    "   \n",
    "#Grab list of market percent returns\n",
    "market_returns_list = get_returns_from_close_df(get_closing_df(['^NYA'], start, end))['^NYA'].values.tolist()\n",
    "del market_returns_list[0]\n",
    "\n",
    "#Runs best_weighting\n",
    "run_weights = threading.Thread(target = best_weighting, args = (market_returns_list, ticklist_final, beta_list, num_hypothetical_portfolios, ))\n",
    "run_weights.start()\n",
    "run_weights.join()\n",
    "\n",
    "#Grab information from queueW\n",
    "while not queueW.empty():\n",
    "   queueWGetter.append(queueW.get())\n",
    "\n",
    "#Initialize variables\n",
    "best_score = 10000 #High so that any given collection of stocks will beat it\n",
    "capm_scores = []\n",
    "\n",
    "#Gets information for CAPM scores, grabs best score, and optimal weights\n",
    "for set_info in range (0, len(queueWGetter)):\n",
    "   capm_scores.append(queueWGetter[set_info][2])\n",
    "\n",
    "   #Check for best score\n",
    "   if queueWGetter[set_info][0] < best_score:\n",
    "      best_score = queueWGetter[set_info][0]\n",
    "      optimal_weighting = queueWGetter[set_info][1]\n",
    "\n",
    "#CAPM scores is a list of lists, so we make it flat\n",
    "capm_scores = [item for sublist in capm_scores for item in sublist]\n",
    "\n",
    "#Percent return over numperiods periods\n",
    "port_expected_return = best_score * 100 * numperiods\n",
    "Portfolio_Final = create_weighted_portfolio(optimal_weighting, tickersPrice_final, capital, price_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final portfolio\n",
    "Portfolio_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ANALYSIS AND SANITY / CORRECTNESS CHECKS:\n",
    "\n",
    "The following cells are where we perform checks to ensure the portfolio is correctly sized and weighted, as well as show visual representations of why this is the optimal portfolio for our goal.\n",
    "\n",
    "THE GOAL:\n",
    "\n",
    "- Ensure the total value of the portfolio is how much capital we allocated to it\n",
    "- Ensure the weights of our stocks add up to 100%\n",
    "- Visually represent the expected return of our portfolio, its performance, and explain why the portfolio is optimal\n",
    "\n",
    "THE PROCESS:\n",
    "\n",
    "We first calculate a simple sum of the value of each security in our portfolio, and a sum of the weights, and ensure they add up to the amount of capital we put into the portfolio, and 100% respectively.\n",
    "\n",
    "Then, we plot the expected returns of a sample of weighted portfolios, as well as the optimal portfolio on a line graph. We mark the optimal portfolio with a star.\n",
    "\n",
    "Next, we provide a \"performance check\", where we can input two days (start and end) and track the returns of our portfolio, compared to a given market, and the expected return of our portfolio.\n",
    "\n",
    "Finally, we graph the returns of our portfolio, the returns of the market, the average return of our portfolio and the market, and the expected return of our portfolio. In our example, we chose a three-month timeline, so that we could include enough data points to show conclusive evidence that our portfolio not only outperforms the market in terms of (lower) volatility but also achieves our desired outcome. We will analyze this graph, and make conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correctness/Sanity Check\n",
    "try:\n",
    "    #Total value and weight of portfolio\n",
    "    val = int(np.round(sum(Portfolio_Final['Value'], 0)))\n",
    "    weight = np.round(sum(Portfolio_Final['Weight'], 0))\n",
    "\n",
    "    print(f\"Total Portfolio Value:  ${val}\")\n",
    "    print(f\"Total Portfolio Weight: {weight * 100}%\")\n",
    "\n",
    "    #Print message depending on whether or not portfolio values are correct\n",
    "    if val == capital and weight == 1:\n",
    "        print(\"\\nEverything is correct!\")\n",
    "    else:\n",
    "        print(\"\\nWeight or Total Value is incorrect.\")\n",
    "except:\n",
    "    print(\"Something went wrong when trying to calculate the value and weight of your portfolio.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that there exists significant variance between the expected returns of differently weighted portfolios shows that our analysis and process for selecting the optimal portfolio is important. (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfolio returns visualization\n",
    "\n",
    "#Must be less than num_hypothetical_portfolios - 1\n",
    "num_data_points = 1000\n",
    "\n",
    "frequency = \"5 Days\"\n",
    "scaler = 100 * numperiods\n",
    "\n",
    "#Indexes for Sample of CAPM scores\n",
    "index_for_graph = np.random.randint(0, (num_hypothetical_portfolios - 1), num_data_points)\n",
    "\n",
    "#Initialize list with best score\n",
    "capm_examples = [best_score * scaler]\n",
    "\n",
    "#Grab 'num_data_points' data points to graph\n",
    "for d in range(num_data_points):\n",
    "    capm_examples.append(capm_scores[index_for_graph[d]] * scaler)\n",
    "\n",
    "#We have 1d data, so all y values are 0\n",
    "y_values = [0] * (num_data_points + 1)\n",
    "\n",
    "# Plot the data, pinpoint best score\n",
    "plt.scatter(capm_examples, y_values, color = 'r')\n",
    "plt.plot(best_score * scaler, 0, marker = '*', color = 'g', ls = 'none', ms = 10, label = 'Best Score')\n",
    "\n",
    "# Set axis and title\n",
    "plt.title(f'Sample of {num_data_points} CAPM Scores from Generation of {num_hypothetical_portfolios} Portfolios')\n",
    "plt.xlabel(f'Expected Return (% {frequency})')\n",
    "plt.xticks(rotation = '70')\n",
    "plt.ylabel('Y-Axis Not Applicable')\n",
    "\n",
    "#Change size of graph\n",
    "plt.gcf().set_size_inches(15, 5)\n",
    "\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can test how the actual returns of our portfolio in a given time period compared to the expected return, as well as the market return.\n",
    "\n",
    "We are using the market as a benchmark because it is the representation of systematic risk. If we can outperform systematic risk, we consider our portfolio a success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance check\n",
    "\n",
    "#Consumes weights, list of tickers, capital, start and end date, returns weekly returns of the portfolio\n",
    "def performance_check(weights, ticker_list, capital, start_set, end_set):\n",
    "    starting = capital\n",
    "    ending = []\n",
    "    returns_port = []\n",
    "    #Ticker objects\n",
    "    ticker_set = [yf.Ticker(ticker) for ticker in ticker_list]  \n",
    "\n",
    "    #For history DataFrame\n",
    "    end = (str((pd.to_datetime(end_set[-1]) + relativedelta(days = 1)).strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "    #Price DataFrames\n",
    "    ticker_data = [ticker.history(start = start_set[0], end  = end)[['Open', 'Close']] for ticker in ticker_set]\n",
    "\n",
    "    #Adds returns\n",
    "    for i in range (0, len(start_set)): \n",
    "        values = []\n",
    "\n",
    "        #Start value of day x is close value of day x - 1\n",
    "        if i > 0:\n",
    "            starting = ending[i - 1]\n",
    "\n",
    "        for j in range(len(ticker_set)):\n",
    "            #Shares if purchased on open of monday and sold on friday\n",
    "            values.append(starting / ticker_data[j].loc[start_set[i], 'Open'] * ticker_data[j].loc[end_set[i], 'Close'])\n",
    "    \n",
    "        ending.append(np.dot(values, weights))\n",
    "\n",
    "        #Percent change in value \n",
    "        returns_port.append((ending[i] - starting) / starting * 100)\n",
    "        \n",
    "    return(returns_port)\n",
    "    \n",
    "#Requires: performance_check_start_date is later than or equal to 'start', performance_check_end_date is earlier than or equal to 'end', both variables are\n",
    "#valid trading days, and performance_check_start_date is earlier than performance_check_end_date\n",
    "performance_check_start_date = '2022-10-31'\n",
    "performance_check_end_date = '2022-11-04'\n",
    "market = 'NYSE'\n",
    "market_ticker = '^NYA'\n",
    "\n",
    "#Get returns\n",
    "market_return = performance_check([1], [market_ticker], capital, [performance_check_start_date], [performance_check_end_date])\n",
    "port_return = performance_check(optimal_weighting, ticklist_final, capital, [performance_check_start_date], [performance_check_end_date])\n",
    "\n",
    "#Summary\n",
    "print(f\"Return of portfolio from {performance_check_start_date} to {performance_check_end_date}: {np.round(port_return[0], 2)}%.\")\n",
    "print(f\"Expected return for time period \\\"{frequency}\\\" for reference: {np.round(port_expected_return, 2)}%.\")\n",
    "print(f\"Return of market \\\"{market}\\\" during this time period for reference: {np.round(market_return[0], 2)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an expanded version of the above performance check which can be used to view the performance of the portfolio over specified intervals of time.\n",
    "\n",
    "The graph shows the returns of the portfolio, the returns of the market, the average return of both, and the expected return of the portfolio.\n",
    "\n",
    "Then, the average distance from a 0% return of the market and the portfolio, the percentage of returns in the portfolio closer to 0 than the market, the standard deviation of portfolio returns, and the beta of our portfolio is stated.\n",
    "    \n",
    "We use this information to assess our portfolio. Specifically, 6 main characteristics should be present:\n",
    "     \n",
    "1. The average return of the portfolio (red line) should be close to the expected return of the portfolio (red dotted line).\n",
    "2. The average and expected return of the portfolio should be closer to 0 (blue dotted / dashed line) than the market average return (green line).\n",
    "3. The average distance from 0% return of our portfolio should be smaller than that of the market.\n",
    "4. There should be a greater percentage of data points from the returns of our portfolio closer to 0 than from the returns of the market.\n",
    "5. The standard deviation of portfolio returns should be relatively low.\n",
    "6. The beta value of the portfolio should be less than 1, and greater than -1.\n",
    "\n",
    "If all of these characteristics are present, we consider the portfolio a success, as this would indicate we have made a good prediction of expected return, beat the market (our benchmark) in terms of our goal, and have a portfolio that is likely to meet our goal if run over a given time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check #2\n",
    "\n",
    "startD_strt = '2022-09-19'#Must be a Monday\n",
    "endD_strt = '2022-09-23'#Must be a Friday\n",
    "weeksPerPeriod = 1\n",
    "\n",
    "start_dSet = [startD_strt]\n",
    "end_dSet = [endD_strt]\n",
    "\n",
    "#We want 9 periods\n",
    "num_periods = 9\n",
    "\n",
    "#Add (num_periods - 1) subsequent (weeksPerPeriod) weeks to start and end sets\n",
    "for i in range (0, num_periods - 1):\n",
    "    start_dSet.append(str((pd.to_datetime(start_dSet[i]) + relativedelta(days = weeksPerPeriod * 7)).strftime(\"%Y-%m-%d\")))\n",
    "    end_dSet.append(str((pd.to_datetime(end_dSet[i]) + relativedelta(days = weeksPerPeriod * 7)).strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "#start_dSet.replace()If there is a monday in your start date set which is a holiday, replace it with the tuesday here\n",
    "#end_dSet.replace()If there is a friday in your end date set which is a holiday, replace it with thursday here\n",
    "\n",
    "#For comparison\n",
    "market = 'NYSE'\n",
    "market_ticker = '^NYA'\n",
    "\n",
    "#Get returns\n",
    "market_returns = performance_check([1], [market_ticker], capital, start_dSet, end_dSet)\n",
    "returns = performance_check(optimal_weighting, tickersPrice_final, capital, start_dSet, end_dSet)\n",
    "\n",
    "# Plot the data, set reference lines for portfolio expected return, actual return, market return, 0\n",
    "plt.scatter(end_dSet, returns, color = 'r', label = 'Portfolio Returns')\n",
    "plt.scatter(end_dSet, market_returns, color = 'g', label = 'Market Returns')\n",
    "plt.axhline(y = port_expected_return, color = 'r', linestyle = ':', label = f'Portfolio Expected Return for period \\\"{frequency}\\\"')\n",
    "plt.axhline(y = np.mean(returns), color = 'r', linestyle = '-', label = 'Portfolio Average Return')\n",
    "plt.axhline(y = np.mean(market_returns), color = 'g', linestyle = '-', label = 'Market Average Return')\n",
    "plt.axhline(y = 0, color = 'b', linestyle = '-.', label = '0% Return')\n",
    "\n",
    "\n",
    "# Set axis and title\n",
    "plt.title(f'Returns of portfolio over intervals of {frequency}')\n",
    "plt.xlabel(f'Date')\n",
    "plt.xticks(rotation = '70')\n",
    "plt.ylabel(f'Return (%)')\n",
    "\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "#Change size of graph\n",
    "plt.gcf().set_size_inches(15, 8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Grab average distance from 0 of data points\n",
    "returns_abs = [abs(x) for x in returns]\n",
    "market_returns_abs = [abs(x) for x in market_returns]\n",
    "returnsADF0 = np.round(np.mean(returns_abs), 2)\n",
    "market_returnsADF0 = np.round(np.mean(market_returns_abs), 2)\n",
    "\n",
    "closer = 0\n",
    "\n",
    "#Calculating amount of times our portfolio is closer to 0% return than the market\n",
    "for i in range(0, len(returns_abs)):\n",
    "    if returns_abs[i] < market_returns_abs[i]:\n",
    "        closer += 1\n",
    "\n",
    "closer = np.round(closer / len(returns_abs) * 100, 2)\n",
    "\n",
    "#DataFrame to store the percent returns of the portfolio and market\n",
    "portfolio_market_stock_pr_df = pd.DataFrame({\"Portfolio\": returns, \"Market Stock\": market_returns})\n",
    "#Beta Calculations of the final portfolio and the market stock\n",
    "market_stock_var = portfolio_market_stock_pr_df[\"Market Stock\"].var()\n",
    "final_portfolio_beta_matrix = portfolio_market_stock_pr_df.cov()/market_stock_var\n",
    "final_portfolio_beta = final_portfolio_beta_matrix.iloc[0,1]\n",
    "\n",
    "#Conclusion\n",
    "print(f\"Absolute average distance from 0% return; portfolio: {returnsADF0}%\")\n",
    "print(f\"Absolute average distance from 0% return; {market}: {market_returnsADF0}%\")\n",
    "print(f\"\\n% of weekly returns in portfolio closer to 0 than {market}: {closer}%\")\n",
    "print(f\"\\nStandard deviation of portfolio returns: {np.round(np.std(returns), 2)}%\")\n",
    "print(f\"Beta of portfolio relative to {market}: {np.round(final_portfolio_beta, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final DataFrame, output to csv\n",
    "Stocks_Final = Portfolio_Final[['Ticker', 'Shares']]\n",
    "Stocks_Final.to_csv(\"Stocks_Group_05.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Our goal was to take in a list of stocks and generate a portfolio that will yield a short-term return as close to 0% as possible. We first cleaned up our data to ensure each ticker we would use represented a stock who met certain criteria. Then, we chose the least volatile stocks to use to generate hypothetical portfolios. We generated one million hypothetical portfolios, and used a modified Capital Asset Pricing Model to obtain the portfolio whose expected return was the closest to zero. Finally, we performed some data analysis, and explained why the portfolio that our code generated is optimal for achieving our goal.\n",
    "\n",
    "There were many ways to create a portfolio which would fulfill our goals, but we hypothesize that our method (apart from noted drawbacks) is the most efficient and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- Various Code and Concepts: Notes of Professor James Thompson\n",
    "- *Weight Generation: https://stackoverflow.com/questions/74527506/creating-a-list-of-n-numbers-between-x-and-y-who-sum-up-to-z\n",
    "- Capital Asset Pricing Model: https://www.investopedia.com/terms/c/capm.asp#toc-the-capm-and-the-efficient-frontier\n",
    "- Robot Image: http://www.onlinewebfonts.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Piero Camposeo, Sathun Suthakaran, Ishaan Bansal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4330579a270bdb9a8676237a34964b41e4839bd986df81befe1ef5b370fe0dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
